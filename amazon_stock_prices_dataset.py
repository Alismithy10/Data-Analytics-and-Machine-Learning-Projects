# -*- coding: utf-8 -*-
"""Amazon Stock Prices Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HvR6IUiRFHOzwmQb-Lv_AhKBR0Pb9qjO

Import and load dataset
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd drive/
# %cd My\ Drive

df = pd.read_csv("Amazon_Stock_Dataset.csv")

"""Import libraries"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.tree import plot_tree
import plotly.graph_objects as go

"""Find and deal with nulls and duplicates"""

print(df.shape)

duplicated_rows_df = df[df.duplicated()]
print("number of duplicated rows: ", duplicated_rows_df.shape)

print("number of nulls: ", df.isnull().sum())

"""Data Visualisation"""

# Basic Line Plot - Prices over Time

plt.figure(figsize=(12, 6))
plt.plot(df['close'], label='Close Price')
plt.title('Amazon Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price ($)')
plt.legend()
plt.grid(True)
plt.show()

# Heatmap - Correlation between features

numerical_features = ['open', 'high', 'low', 'close', 'adj_close', 'volume']
plt.figure(figsize=(10, 6))
sns.heatmap(df[numerical_features].corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Between Features")
plt.show()

# Candlestick Chart - Interactive

fig = go.Figure(data=[go.Candlestick(
    x=df.index,
    open=df['open'],
    high=df['high'],
    low=df['low'],
    close=df['close']
)])
fig.update_layout(title='AMZN Candlestick Chart', xaxis_title='Date', yaxis_title='Price')
fig.show()

"""Construct a model


"""

# Decision Tree Regressor

features = ['open',  'high', 'low', 'volume']
X = df[features]
y = df['close']

print(X.head())
print(y[0:5])

"""Split into training and testing datasets"""

X_train, X_test, y_train, y_test = train_test_split(X, y)

print(X_train.shape)

"""Create and train object"""

model = DecisionTreeRegressor(
    max_depth=11, min_samples_split=10, min_samples_leaf=5, random_state=42
    )

model = model.fit(X_train, y_train)

"""Test dataset and print Mean Squared Error and R^2 Score"""

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")

"""Visualise the prediction"""

plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs Predicted")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # identity line
plt.grid(True)
plt.show()

"""# Conclusion

Throughout this notebook the Amazon Stock prices dataset from 2012 to 2025 was analysed to inspect links and trends. A decision tree regressor was then created, trained, and tested achieving a Mean Squared Error of 1.34 and an R^2 Score of 0.9996, 99.96% (rounded up to 2 decimals) suggesting that the model is on average the difference between predicated and actual values is very small and that the model is .04% away from perfectly predicting the values, showing it is a highly reliable model.
"""